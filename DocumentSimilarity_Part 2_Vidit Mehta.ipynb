{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Output of comparison of MinHash and Jacard Values for a small subset of 100 dataset \n",
      "\n",
      "      ID1    ID2  MinHash Value Plagiarism  JS Value\n",
      "0    t980  t1088            0.0         No  0.245677\n",
      "1    t980  t1233            0.0         No  0.245677\n",
      "2    t980  t1235            0.0         No  0.245677\n",
      "3    t980  t1297            0.0         No  0.245677\n",
      "4    t980  t1768            0.0         No  0.245677\n",
      "5   t1088  t1233            0.0         No  0.245677\n",
      "6   t1088  t1235            0.0         No  0.245677\n",
      "7   t1088  t1297            0.0         No  0.245677\n",
      "8   t1088  t1768            0.0         No  0.245677\n",
      "9   t1233  t1235            0.0         No  0.245677\n",
      "10  t1233  t1297            0.0         No  0.245677\n",
      "11  t1233  t1768            0.0         No  0.245677\n",
      "12  t1235  t1297            0.0         No  0.245677\n",
      "13  t1235  t1768            0.0         No  0.245677\n",
      "14  t1297  t1768            0.0         No  0.245677\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------\n",
    "# Code required towards ground work for Part 2\n",
    "#-------------------------------------------------------------------------------------- \n",
    "\n",
    "import string\n",
    "import binascii\n",
    "import pandas as pd\n",
    "from sklearn import linear_model                            \n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Dataset parsing\n",
    "#-------------------------------------------------------------------------------------- \n",
    "def parse_data(testfile):                                    # testfile = Path of file, stored locally on my system\n",
    "    final_list = []\n",
    "    fd = open(testfile,\"r\")                                  # opening file in read mode\n",
    "    for line in fd:\n",
    "        ids = []\n",
    "        text = []\n",
    "        tup = ()\n",
    "        a = line.split()                                    # getting the contents of the first line in the document\n",
    "        ids.append(a[0])                                    # extracting the document ID\n",
    "        idtup = tuple(ids)\n",
    "        del a[0]\n",
    "        article = ''\n",
    "        for word in a:\n",
    "            word = word.lower()                             # converting to lower case\n",
    "            word = word.translate(str.maketrans('','',string.punctuation)) # removing all punctuations\n",
    "            article = article + word                        # creating a concatenated string of all the words in the article\n",
    "        text.append(article)\n",
    "        articletup = tuple(text)\n",
    "        tup = idtup + articletup\n",
    "        final_list.append(tup)\n",
    "    return tuple(final_list)\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Creating Document Shingles\n",
    "#-------------------------------------------------------------------------------------- \n",
    "def shingle_document(t,k):\n",
    "    docAsShingles = {}\n",
    "    for i in t:\n",
    "        docID = i[0]                                        # Extracting the document ID\n",
    "        s = i[1]                                            # The article text\n",
    "        shinglesInArticle = set()\n",
    "        for j in range(0,len(s)-k+1):                       # looping through each character\n",
    "            shingle = ''\n",
    "            for m in range(j,j+k):                          # Loop to create shingles\n",
    "                shingle = shingle + s[m]\n",
    "            crc = binascii.crc32(shingle.encode()) & 0xffffffff  # To get the 32-bit hashed integer\n",
    "            shinglesInArticle.add(crc)                      # Adding the shingles to a set\n",
    "        docAsShingles[docID] = shinglesInArticle            # Storing values in a dict object\n",
    "    return docAsShingles\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Computing Jaccard Similarity\n",
    "#-------------------------------------------------------------------------------------- \n",
    "def jaccard(l):\n",
    "    flist = []\n",
    "    k = l.items()                                           # To extract shingle and docIDs\n",
    "    id = [x for x,_ in k]                                   # Extracting the document IDs through a list comprehension\n",
    "    for i in range(0,len(id)):\n",
    "        id1 = tuple([id[i]])                                # Extracting 1st DocID, converting to a list, then to a tuple\n",
    "        s1 = l[id[i]]\n",
    "        for j in range(i+1,len(id)):\n",
    "            m = []\n",
    "            tup = ()\n",
    "            id2 = tuple([id[j]])\n",
    "            s2 = l[id[j]]\n",
    "            js = (len(s1 & s2)/len(s1 | s2))                # Computing Jaccard Similarity\n",
    "            if js > 0.99:\n",
    "                plagiarism = ['Yes']                        # Setting Plagiarism Flag to Yes if JS value>0.99\n",
    "            else:\n",
    "                plagiarism = ['No']\n",
    "            m.append(js)\n",
    "            tup = id1 + id2 + tuple(m) + tuple(plagiarism)\n",
    "            flist.append(tup)\n",
    "    return tuple(flist)\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Start of <<<<<<<<<<<_Part 2_>>>>>>>>>>>\n",
    "#-------------------------------------------------------------------------------------- \n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Part 2A Preparing Shingles for MinHash\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "def invert_shingles(l):                                     # Argument l = The dict containing (docID, shingle) pairs\n",
    "    flist = []\n",
    "    k = l.items()                                           # To extract shingle and docIDs, returns list of tuple pairs\n",
    "    id = [x for x,_ in k]\n",
    "    for i in range(0,len(id)):\n",
    "        docid = tuple([id[i]])\n",
    "        shingles = l[id[i]]\n",
    "        m = []\n",
    "        for s in shingles:\n",
    "            tup = ()\n",
    "            tup = tuple([s]) + docid\n",
    "            m.append(tup)\n",
    "        m.sort(key = lambda tup: tup[0])                    # Sorting the tuple entries\n",
    "        flist.append(m)\n",
    "    return id, tuple(flist)\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Part 2B Generate Hash Functions\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "DEFAULT_P = 2**33-355\n",
    "DEFAULT_M = 4294967295\n",
    "\n",
    "def getHashCoeffs(num_hashes, m=DEFAULT_M):\n",
    "    randList = []\n",
    "    while num_hashes > 0:\n",
    "        randIndex = random.randint(0, m)\n",
    "        while randIndex in randList:\n",
    "            randIndex = random.randint(0, m)\n",
    "        randList.append(randIndex)\n",
    "        num_hashes = num_hashes - 1\n",
    "    return randList\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Part 2C Construct the MinHash Signature Matrix\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "def make_minhash_signature(l, id, a, b, num_hashes, p=DEFAULT_P):\n",
    "    signatures = []                                                   # Master list to hold signatures\n",
    "    for i in range(0,len(id)):\n",
    "        docid = tuple([id[i]])                                  \n",
    "        shingles = l[id[i]]\n",
    "        signature = []\n",
    "        for j in range(0,num_hashes):                                 # Looping through all the hash functions\n",
    "            minHashCode = p + 1\n",
    "            for s in shingles:\n",
    "                hashCode = (a[i] * s + b[i]) % p                      # Applying Hashfunction to shingle s\n",
    "                if hashCode < minHashCode:\n",
    "                    minHashCode = hashCode\n",
    "            signature.append(minHashCode)\n",
    "        signatures.append(signature)\n",
    "    return signatures\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Part 2D Getting MinHash Similarity Estimate\n",
    "#--------------------------------------------------------------------------------------\n",
    "        \n",
    "def minhash_similarity(id, num_hashes, signatures):\n",
    "    result = []\n",
    "    for i in range(0, len(id)):\n",
    "        signature1 = signatures[i]\n",
    "        id1 = tuple([id[i]])\n",
    "        for j in range(i + 1, len(id)):\n",
    "            m = []\n",
    "            tup = ()\n",
    "            signature2 = signatures[j]\n",
    "            id2 = tuple([id[j]])\n",
    "            count = 0\n",
    "            for k in range(0, num_hashes):\n",
    "                count = count + (signature1[k] == signature2[k])   # getting the count of min hash values for a pair of docs\n",
    "            sim = (count / num_hashes)\n",
    "            if sim > 0.99:                                  # Setting Plagiarism flag to Yes if sim > 0.99 (threshold value) \n",
    "                plagiarism = ['Yes']                        \n",
    "            else:\n",
    "                plagiarism = ['No']\n",
    "            m.append(sim)\n",
    "            tup = id1 + id2 + tuple(m) + tuple(plagiarism)\n",
    "            result.append(tup)\n",
    "    return tuple(result)\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Part 2E Putting it all together, test results for a subset of 100 file\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "DEFAULT_P = 2**33-355\n",
    "DEFAULT_M = 4294967295\n",
    "num_hashes = 10\n",
    "testfile = r'C:\\Vidit\\PhD\\Fall 2018\\CMSC 643 - Hector\\Project 1\\TestFile.txt'\n",
    "t = parse_data(testfile)                                                # Parsing data file\n",
    "l = shingle_document(t,3)                                               # Shingling\n",
    "j = jaccard(l)                                                          # Getting Jacard values\n",
    "id, docs = invert_shingles(l)                                           # Inverting the shingles\n",
    "a = getHashCoeffs(num_hashes, DEFAULT_M)                                # Getting coefficient A\n",
    "b = getHashCoeffs(num_hashes, DEFAULT_M)                                # Getting coefficient B\n",
    "signatures = make_minhash_signature(l, id, a, b, num_hashes, DEFAULT_P) # Getting signatures\n",
    "m = minhash_similarity(id, num_hashes, signatures)                      # Getting minhash similarity estimates\n",
    "r = []\n",
    "for b in j:\n",
    "    j1 = tuple([b[2]])\n",
    "for i in m:\n",
    "    i = i + j1\n",
    "    r.append(i)\n",
    "df = pd.DataFrame(r, columns=['ID1', 'ID2', 'MinHash Value','Plagiarism','JS Value'])\n",
    "print (\"\\n Output of comparison of MinHash and Jacard Values for a small subset of 100 dataset \\n\")\n",
    "print (df)\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Part 2F Experiment 1\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "def run_experiment(id, signatures,k,\n",
    "                   num_hashes = [10,20,40,60,80,100,120]):\n",
    "    testfile = r'C:\\Vidit\\PhD\\Fall 2018\\CMSC 643 - Hector\\Project 1\\TestFile1000.txt'\n",
    "    for i in num_hashes:\n",
    "        t = parse_data(testfile)                                                # Parsing data file\n",
    "        l = shingle_document(t,k)                                               # Shingling\n",
    "        j = jaccard(l)                                                          # Getting Jacard values\n",
    "        id, docs = invert_shingles(l)                                           # Inverting the shingles\n",
    "        a = getHashCoeffs(i, DEFAULT_M)                                         # Getting coefficient A\n",
    "        b = getHashCoeffs(i, DEFAULT_M)                                         # Getting coefficient B\n",
    "        signatures = make_minhash_signature(l, id, a, b, num_hashes, DEFAULT_P) # Getting signatures\n",
    "        m = minhash_similarity(id, i, signatures)                               # Getting minhash similarity estimates\n",
    "        r = []\n",
    "        for b in j:\n",
    "            j1 = tuple([b[2]])\n",
    "        for k in m:\n",
    "            k = i + j1\n",
    "            r.append(k)\n",
    "            r.append(i)\n",
    "    df = pd.DataFrame(r, columns=['ID1', 'ID2', 'MinHash Value','Plagiarism','JS Value','Num_Hashes'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
